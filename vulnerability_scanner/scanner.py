#!/root/anaconda3/bin  python

import requests
import re
import urllib
import time
from bs4 import BeautifulSoup


class Scanner(object):

    def __init__(self, url, ignore_links):
        self.session = requests.Session()
        self.target_url = url
        self._target_links = set()
        self.links_to_ignore = ignore_links

    def request(self, url):
        try:
            if not 'http' in url:
                return self.session.get(f'http://{url}')
            else:
                return requests.get(url)
        except requests.exceptions.ConnectionError:
            pass
        except NameError as err:
            print(f'NameError: {err}')
        except requests.exceptions.InvalidURL as err:
            print(f'Invalid URL: {err}')
        except UnicodeError as err:
            print(f'UnicodeError: {err}')

    def extract_links_from(self, url):
        responce = self.request(url)
        return re.findall('(?:href=")(.*?)"', responce.content.decode("latin1")) if responce else None

    def crawl(self):
        links = self.extract_links_from(self.target_url)
        if links is not None:
            for link_ in links:
                link = urllib.parse.urlparse(target_url, link_)
                if not 'http' in link.scheme:
                    p_link = re.sub(r'\.$', '', link.scheme)
                    link = f"http://{link.path}{p_link}"
                else:
                    link = link.scheme
                if target_url in link:
                    if '#' in link:
                        link = link.split('#')[0]
                    if link not in self._target_links and link not in self.links_to_ignore:
                        self._target_links.add(link)
                        self.target_url = link
                        self.crawl()

    @property
    def target_links(self):
        return self._target_links

    @property
    def print_links(self):
        for link in self.target_links:
            print(link)
        return self.target_links

    def extract_forms(self, target_url):
        response = self.session.get(target_url).content.decode("latin1")
        parsed_html = BeautifulSoup(response)
        return parsed_html.findAll('form')

    def submit_form(self, form, value, target_url):
        action = form.get('action')
        post_url = f'{target_url}{action if action else ""}'

        method_ = form.get('method')

        post_data = {}
        inputs_list = form.findAll('input')
        for input_ in inputs_list:
            input_name = input_.get('name')
            input_type = input_.get('type')
            if input_type == 'text':
                input_value = value
            else:
                input_value = input_.get('value')

            post_data[input_name] = input_value

        if method_.lower() == 'post':
            return self.session.post(post_url, data=post_data).content.decode()
        return self.session.get(post_url, params=post_data).content.decode()

    def run_scanner(self):
        for link in self.target_links:
            forms = self.extract_forms(link)
            for form in forms:
                print(f"\n\n[+] Testing from in {link}")
                if self.test_xss_in_form(form, link):
                    print(
                        f'[***] XSS discovered in {link} in the following form: {form}')

            if '=' in link:
                print(f"\n\n[+] Testing {link}")
                if self.test_xss_in_link(link):
                    print(
                        f'[***] Discorvered XSS in link :{link}')

    def test_xss_in_form(self, form, url, xss_test_script="<sCript>alert('test')</scriPt>"):
        responce = self.submit_form(form, xss_test_script, url)
        return xss_test_script in responce

    def test_xss_in_link(self, url, xss_test_script="<sCript>alert('test')</scriPt>"):
        url = url.replace('=', f'={xss_test_script}')
        responce = self.session.get(url).content.decode()
        return xss_test_script in responce


if __name__ == '__main__':
    target_url = '192.168.1.127/dvwa/'
    links_to_ignore = {'http://192.168.1.127/dvwa/logout.php'}
    data_dict = {'username': 'admin',
                 'password': 'password', 'Login': 'submit'}
    vuln_scanner = Scanner(target_url, links_to_ignore)
    vuln_scanner.session.post(
        f'http://{target_url}login.php', data=data_dict)
    vuln_scanner.crawl()
    vuln_scanner.run_scanner()

    # time.sleep(3)

    # forms = vuln_scanner.extract_forms('http://192.168.1.127/dvwa/vulnerabilities/xss_r/')
    # print(vuln_scanner.test_xss_in_form(forms[0],
    #     "http://192.168.1.127/dvwa/vulnerabilities/xss_r/"))
    # print(vuln_scanner.test_xss_in_link(
    #     "http://192.168.1.127/dvwa/vulnerabilities/xss_r/?name=test"))
